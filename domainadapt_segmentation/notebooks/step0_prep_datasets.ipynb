{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pickle as pkl\n",
    "import os \n",
    "def make_dataset_tuple(my_df, phase_label=-1):\n",
    "    test_l, train_l, val_l = list(), list(), list()\n",
    "    for i, e in my_df.iterrows():\n",
    "        row = {}\n",
    "        row[\"image\"] = e[\"vol\"]\n",
    "        row[\"lbl\"] = e[\"lbl\"]\n",
    "        row[\"phase\"] = phase_label\n",
    "        if e[\"split\"] == \"train\":\n",
    "            train_l.append(row)\n",
    "        if e[\"split\"] == \"test\":\n",
    "            test_l.append(test_l)\n",
    "        if e[\"split\"] == \"val\":\n",
    "            val_l.append(val_l)\n",
    "    tup = (train_l, val_l, test_l)\n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file simply contains the paths to  the kits21 and STU datasets \n",
    "with open(\"../../secrets_folder/paths_info.json\",\"r\") as f: \n",
    "    path_dir = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "kits_meta_path = os.path.join(path_dir['KITS21DIR'],'kits.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Kits datasets \n",
    "- Kits data contains a json file specifying case ids we use that to specify the paths to our images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(kits_meta_path, \"r\") as f:\n",
    "    kits_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "kits_df = pd.DataFrame(kits_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is where the images were downloaded to\n",
    "data_dir = path_dir['KITS21DIR'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kits is organized in a verify simple structure so we can find imaging and segmentation using\n",
    "kits_df[\"vol\"] = kits_df[\"case_id\"].apply(\n",
    "    lambda x: os.path.join(data_dir, x, \"imaging.nii.gz\")\n",
    ")\n",
    "kits_df[\"lbl\"] = kits_df[\"case_id\"].apply(\n",
    "    lambda x: os.path.join(data_dir, x, \"segmentation.nii.gz\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is split into train,test,validation usign this seed\n",
    "train, val = train_test_split(sorted(kits_df[\"case_id\"].unique()), random_state=1996)\n",
    "val, test = train_test_split(val, random_state=1996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "kits_df[\"split\"] = \"ukw\"\n",
    "kits_df.loc[kits_df[\"case_id\"].isin(train), \"split\"] = \"train\"\n",
    "kits_df.loc[kits_df[\"case_id\"].isin(val), \"split\"] = \"val\"\n",
    "kits_df.loc[kits_df[\"case_id\"].isin(test), \"split\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the data into the form expected by the monai dataloader\n",
    "# we make the phase label 1 as the entire kits is contrast phase\n",
    "kits_tup = make_dataset_tuple(kits_df, phase_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it to your datasets file\n",
    "with open(\"./datasets/kits21.pkl\", \"wb\") as f:\n",
    "    pkl.dump(kits_tup, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the STU Dataset \n",
    "- In this case we have a folder containing image and masks with a covnenient naming structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "stu_dataset_dir =  path_dir['STUDIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [str(e) for e in Path(stu_dataset_dir).rglob(\"*image.nii.gz\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = [e.replace(\"image\", \"mask\") for e in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stu_df = pd.DataFrame({\"vol\": images, \"lbl\": masks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stu_pid(s):\n",
    "    return s.split(\"/\")[-1].split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stu_df[\"case_id\"] = stu_df[\"vol\"].apply(get_stu_pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same stratergy for splitting\n",
    "train, val = train_test_split(sorted(stu_df[\"case_id\"].unique()), random_state=1996)\n",
    "val, test = train_test_split(val, random_state=1996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "stu_df[\"split\"] = \"ukw\"\n",
    "stu_df.loc[stu_df[\"case_id\"].isin(train), \"split\"] = \"train\"\n",
    "stu_df.loc[stu_df[\"case_id\"].isin(val), \"split\"] = \"val\"\n",
    "stu_df.loc[stu_df[\"case_id\"].isin(test), \"split\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we make the phase label 0 because\n",
    "stu_tup = make_dataset_tuple(stu_df, phase_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./datasets/stu.pkl\", \"wb\") as f:\n",
    "    pkl.dump(stu_tup, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check step1 for making the combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('domain_adapt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f8b0103c6092bfcd6a59b465cd73b68dcfa880bdf682f3f6717d94df1cbb76f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
