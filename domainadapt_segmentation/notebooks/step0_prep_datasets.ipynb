{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pickle as pkl\n",
    "#this is a one file modification\n",
    "\n",
    "def make_dataset_tuple(my_df, phase_label=-1):\n",
    "    test_l, train_l, val_l = list(), list(), list()\n",
    "    for i, e in my_df.iterrows():\n",
    "        row = {}\n",
    "        row[\"image\"] = e[\"vol\"]\n",
    "        row[\"lbl\"] = e[\"lbl\"]\n",
    "        row[\"phase\"] = phase_label\n",
    "        if e[\"split\"] == \"train\":\n",
    "            train_l.append(row)\n",
    "        if e[\"split\"] == \"test\":\n",
    "            test_l.append(test_l)\n",
    "        if e[\"split\"] == \"val\":\n",
    "            val_l.append(val_l)\n",
    "    tup = (train_l, val_l, test_l)\n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Kits datasets \n",
    "- Kits data contains a json file specifying case ids we use that to specify the paths to our images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/mnt/storage/kits23/dataset/kits23.json\", \"r\") as f:\n",
    "    kits_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kits_df = pd.DataFrame(kits_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is where the images were downloaded to\n",
    "data_dir = \"/mnt/storage/kits23/dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kits is organized in a verify simple structure so we can find imaging and segmentation using\n",
    "kits_df[\"vol\"] = kits_df[\"case_id\"].apply(\n",
    "    lambda x: os.path.join(data_dir, x, \"imaging.nii.gz\")\n",
    ")\n",
    "kits_df[\"lbl\"] = kits_df[\"case_id\"].apply(\n",
    "    lambda x: os.path.join(data_dir, x, \"segmentation.nii.gz\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is split into train,test,validation usign this seed\n",
    "train, val = train_test_split(sorted(kits_df[\"case_id\"].unique()), random_state=1996)\n",
    "val, test = train_test_split(val, random_state=1996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kits_df[\"split\"] = \"ukw\"\n",
    "kits_df.loc[kits_df[\"case_id\"].isin(train), \"split\"] = \"train\"\n",
    "kits_df.loc[kits_df[\"case_id\"].isin(val), \"split\"] = \"val\"\n",
    "kits_df.loc[kits_df[\"case_id\"].isin(test), \"split\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the data into the form expected by the monai dataloader\n",
    "# we make the phase label 1 as the entire kits is contrast phase\n",
    "kits_tup = make_dataset_tuple(kits_df, phase_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kits_df[\"vol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it to your datasets file\n",
    "with open(\"../datasets/kits23.pkl\", \"wb\") as f:\n",
    "    pkl.dump(kits_tup, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the STU Dataset \n",
    "- In this case we have a folder containing image and masks with a covnenient naming structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stu_dataset_dir = \"/mnt/storage/ramon_data_curations/STU_noncon_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(stu_dataset_dir)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [str(e) for e in Path(stu_dataset_dir).rglob(\"*image.nii.gz\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = [e.replace(\"image\", \"mask\") for e in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stu_df = pd.DataFrame({\"vol\": images, \"lbl\": masks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stu_pid(s):\n",
    "    return s.split(\"/\")[-1].split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stu_df[\"case_id\"] = stu_df[\"vol\"].apply(get_stu_pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same stratergy for splitting\n",
    "train, val = train_test_split(sorted(stu_df[\"case_id\"].unique()), random_state=1996)\n",
    "val, test = train_test_split(val, random_state=1996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stu_df[\"split\"] = \"ukw\"\n",
    "stu_df.loc[stu_df[\"case_id\"].isin(train), \"split\"] = \"train\"\n",
    "stu_df.loc[stu_df[\"case_id\"].isin(val), \"split\"] = \"val\"\n",
    "stu_df.loc[stu_df[\"case_id\"].isin(test), \"split\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we make the phase label 0 because\n",
    "stu_tup = make_dataset_tuple(stu_df, phase_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../datasets/stu.pkl\", \"wb\") as f:\n",
    "    pkl.dump(stu_tup, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check step2 for making the combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rad_euro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
